{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "C4W2_Assignment.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dionisispriftis/CIFAR10-Autoencoder/blob/main/C4W2_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6S2HVAkSt0p"
      },
      "source": [
        "# Week 2 Assignment: CIFAR-10 Autoencoder\n",
        "\n",
        "Dataset: [CIFAR10](https://www.tensorflow.org/datasets/catalog/cifar10)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1mzy2J8_nc1"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EXwoz-KHtWO"
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2Gs6Lyc_pd0"
      },
      "source": [
        "## Load and prepare the dataset\n",
        "\n",
        "The [CIFAR 10](https://www.tensorflow.org/datasets/catalog/cifar10) dataset already has train and test splits and you can use those in this exercise. Here are the general steps:\n",
        "\n",
        "* Load the train/test split from TFDS. Set `as_supervised` to `True` so it will be convenient to use the preprocessing function we provided.\n",
        "* Normalize the pixel values to the range [0,1], then return `image, image` pairs for training instead of `image, label`. This is because you will check if the output image is successfully regenerated after going through your autoencoder.\n",
        "* Shuffle and batch the train set. Batch the test set (no need to shuffle).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9F7YsCNIKSA"
      },
      "source": [
        "# preprocessing function\n",
        "def map_image(image, label):\n",
        "  image = tf.cast(image, dtype=tf.float32)\n",
        "  image = image / 255.0\n",
        "\n",
        "  return image, image # dataset label is not used. replaced with the same image input.\n",
        "\n",
        "# parameters\n",
        "BATCH_SIZE = 64\n",
        "SHUFFLE_BUFFER_SIZE = 1024\n",
        "\n",
        "# use tfds.load() to fetch the 'train' split of CIFAR-10\n",
        "train_dataset = tfds.load(name='cifar10', split='train', as_supervised=True)\n",
        "\n",
        "# preprocess the dataset with the `map_image()` function above\n",
        "train_dataset = train_dataset.map(map_image)\n",
        "\n",
        "# shuffle and batch the dataset\n",
        "train_dataset = train_dataset.shuffle(1024).batch(BATCH_SIZE)\n",
        "\n",
        "\n",
        "# use tfds.load() to fetch the 'test' split of CIFAR-10\n",
        "test_dataset = tfds.load(name='cifar10', split='test', as_supervised=True)\n",
        "\n",
        "# preprocess the dataset with the `map_image()` function above\n",
        "test_dataset = test_dataset.map(map_image)\n",
        "\n",
        "# batch the dataset\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPyOgGJs_t98"
      },
      "source": [
        "## Build the Model\n",
        "\n",
        "Create the autoencoder model. We'll downsample the image in the encoder layers then upsample it in the decoder path. Note that the output layer should be the same dimensions as the original image. Input images have the shape `(32, 32, 3)`. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wr-Bok3lRgA3"
      },
      "source": [
        "from keras.layers import Conv2D, UpSampling2D\n",
        "\n",
        "input = tf.keras.layers.Input(shape=(32,32,3,))\n",
        "\n",
        "# encoder\n",
        "x = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation = 'relu', padding='same')(input)\n",
        "x = tf.keras.layers.MaxPooling2D()(x)\n",
        "x = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation = 'relu', padding='same')(x)\n",
        "\n",
        "encoder_output = tf.keras.layers.MaxPooling2D()(x)\n",
        "encoder_visualization = tf.keras.layers.Conv2D(filters=3, kernel_size=(3,3), activation = 'sigmoid', padding='same')(encoder_output)\n",
        "\n",
        "# decoder\n",
        "\n",
        "x = tf.keras.layers.UpSampling2D()(encoder_output)\n",
        "x = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation = 'relu', padding='same')(x)\n",
        "x = tf.keras.layers.UpSampling2D()(x)\n",
        "\n",
        "decoder_output = tf.keras.layers.Conv2D(filters=3, kernel_size=(3,3), activation = 'sigmoid', padding='same')(x)\n",
        "\n",
        "encoder_model = tf.keras.Model(inputs = input, outputs = encoder_visualization)\n",
        "model = tf.keras.Model(inputs = input, outputs = decoder_output)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRWTAijKEVUC"
      },
      "source": [
        "## Configure training parameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHIeD9eDETSk"
      },
      "source": [
        "model.compile(optimizer='adam', metrics=['accuracy'], loss='mean_squared_error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLQPhm1W_8dC"
      },
      "source": [
        "## Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMBimOnsRvg0"
      },
      "source": [
        "# parameters (feel free to change this)\n",
        "train_steps = len(train_dataset) // BATCH_SIZE \n",
        "val_steps = len(test_dataset) // BATCH_SIZE\n",
        "\n",
        "EPOCHS = 15\n",
        "\n",
        "model.fit(train_dataset, epochs=EPOCHS, validation_data=test_dataset)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PT2l1c-SAaF4"
      },
      "source": [
        "## Model evaluation\n",
        "\n",
        "You can use this code to test your model locally before uploading to the grader. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFncgqahSQhA"
      },
      "source": [
        "result = model.evaluate(test_dataset, steps=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FPW8Q6R9AOp"
      },
      "source": [
        "test_images = test_dataset.take(1)\n",
        "encoder_images = encoder_model.predict(test_images)\n",
        "decoder_images = model.predict(test_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpbSvSwPj_gm"
      },
      "source": [
        "input_images = []\n",
        "for image in test_images:\n",
        "  input_images.append(image[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aav-EEw89TgT"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DSXqEiI90_0"
      },
      "source": [
        "examples = 10\n",
        "idx = np.random.randint(0,len(decoder_images)-1,size = examples)\n",
        "\n",
        "fig, ax = plt.subplots(3, examples, figsize = (20,6))\n",
        "\n",
        "for i in range(examples):\n",
        "  ax[0,i].imshow(input_images[0][idx[i]])\n",
        "  ax[1,i].imshow(encoder_images[idx[i]])\n",
        "  ax[2,i].imshow(decoder_images[idx[i]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypUogrqFJKgJ"
      },
      "source": [
        "encoder_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaRSkQPNAPT0"
      },
      "source": [
        "## Save your model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLFpLP-c7rDR"
      },
      "source": [
        "#model.save('mymodel.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}